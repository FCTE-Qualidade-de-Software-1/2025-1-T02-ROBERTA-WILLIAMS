# üìë Avalia√ß√£o de Qualidade e Gest√£o do Projeto AgroMart

## 1. Vis√£o Geral do Projeto

O AgroMart √© um sistema que apoia as opera√ß√µes de uma agropecu√°ria multicanal, abrangendo vendas de ra√ß√µes, medicamentos veterin√°rios, sementes, adubos e produtos de higiene animal. Diante do alto volume de produtos e do atendimento diversificado ao cliente, **avaliar e aprimorar a qualidade do sistema** torna-se essencial para garantir efici√™ncia operacional, satisfa√ß√£o do cliente e escalabilidade do neg√≥cio.

---

## 2. Fase 1 ‚Äì Prop√≥sito da Avalia√ß√£o

### 2.1 Objetivo Geral
Avaliar a qualidade do AgroMart segundo a norma **ISO/IEC 25010**, de modo a:  
‚Ä¢ Identificar pontos fortes e fracos do sistema;  
‚Ä¢ Priorizar a√ß√µes de melhoria;  
‚Ä¢ Sustentar o crescimento do neg√≥cio com processos confi√°veis.

### 2.2 Justificativa
‚Ä¢ **Fluidez de vendas**: reduzir tempos e cliques em balc√£o.  
‚Ä¢ **Confiabilidade de estoque**: mitigar inconsist√™ncias que geram retrabalho.  
‚Ä¢ **Satisfa√ß√£o do cliente**: atendimento √°gil e informa√ß√£o clara.  
‚Ä¢ **Suporte ao crescimento**: manter qualidade com expans√£o de cat√°logo e filiais.

### 2.3 Stakeholders
| Categoria | Exemplos | Interesse Principal |
|-----------|----------|---------------------|
| Usu√°rios Finais | Atendentes, vendedores | Velocidade de registro de vendas |
| Clientes | Agricultores, pecuaristas | Agilidade e precis√£o de informa√ß√£o |
| Equipe Administrativa | Gerentes, financeiro | Controle de estoque/receita |
| Equipe T√©cnica | Desenvolvedores, suporte | Facilidade de manuten√ß√£o |

### 2.4 Caracter√≠sticas de Qualidade Focadas
Com base na ISO/IEC 25010, o time definiu inicialmente cinco caracter√≠sticas (Usabilidade, Desempenho, Confiabilidade, Manutenibilidade, Portabilidade). **Posteriormente, o escopo foi refinado para concentrar-se unicamente na caracter√≠stica de Usabilidade**, considerada cr√≠tica para acelerar vendas e reduzir curva de aprendizado.

### 2.5 Resultados Esperados
‚Ä¢ Diagn√≥stico completo de usabilidade;  
‚Ä¢ M√©tricas que sustentem decis√µes de UI/UX;  
‚Ä¢ Plano de a√ß√£o priorizado para corre√ß√µes;  
‚Ä¢ Melhoria percept√≠vel na satisfa√ß√£o dos usu√°rios-chave.

---

## 3. Fase 2 ‚Äì Especificar a Avalia√ß√£o (Foco em Usabilidade)

### 3.1 Subcaracter√≠sticas de Usabilidade Selecionadas
| Subcaracter√≠stica | Defini√ß√£o ISO/IEC 25010 | Contexto AgroMart | Prioridade |
|-------------------|-------------------------|-------------------|-----------|
| Reconhecimento de Adequa√ß√£o | Usu√°rio percebe que o sistema atende √†s necessidades | Vendedores encontram fun√ß√µes de venda rapidamente | Alta |
| Capacidade de Aprendizado | Facilidade de aprender a usar | Onboarding r√°pido de novos colaboradores | **Muito Alta** |
| Operabilidade | Facilidade de executar tarefas | Registro de vendas sem atrito | **Muito Alta** |
| Prote√ß√£o ao Erro | Sistema previne/detecta erros | Evitar vendas duplicadas | Alta |
| Est√©tica da Interface | Interface agrad√°vel | Layout motivador para uso di√°rio | M√©dia |
| Acessibilidade | Uso por pessoas com limita√ß√µes | Inclus√£o de diversos perfis | M√©dia |

#### 3.1.1 Justificativa da Prioriza√ß√£o
1. **Capacidade de Aprendizado** e **Operabilidade**: impactam diretamente as margens de lucro e produtividade.  
2. **Reconhecimento de Adequa√ß√£o** e **Prote√ß√£o ao Erro**: afetam percep√ß√£o de utilidade e confiabilidade.  
3. **Est√©tica** e **Acessibilidade**: contribuem para satisfa√ß√£o e inclus√£o.

### 3.2 M√©tricas e Crit√©rios de Aceita√ß√£o
| Subcaracter√≠stica | M√©trica | Unidade | M√≠nimo | Desejado |
|-------------------|---------|---------|--------|----------|
| Reconhecimento de Adequa√ß√£o | Taxa de reconhecimento de funcionalidade | % | ‚â• 80 | ‚â• 95 |
|  | Tempo p/ identificar fun√ß√£o | s | ‚â§ 60 | ‚â§ 30 |
| Capacidade de Aprendizado | Tempo de aprendizado inicial | min | ‚â§ 30 | ‚â§ 15 |
|  | Taxa de reten√ß√£o de conhecimento | % | ‚â• 70 | ‚â• 90 |
|  | Curva de aprendizado | tarefas/dia | ‚â• 5 | ‚â• 10 |
| Operabilidade | Tempo de execu√ß√£o de tarefa | s | ‚â§ 120 | ‚â§ 60 |
|  | Taxa de conclus√£o de tarefa | % | ‚â• 80 | ‚â• 95 |
|  | Efici√™ncia de navega√ß√£o | cliques | ‚â§ 8 | ‚â§ 5 |
| Prote√ß√£o ao Erro | Taxa de erros do usu√°rio | % | ‚â§ 10 | ‚â§ 5 |
|  | Taxa de recupera√ß√£o de erros | % | ‚â• 80 | ‚â• 95 |
| Est√©tica da Interface | Satisfa√ß√£o visual | 1-5 | ‚â• 3 | ‚â• 4 |
|  | Atratividade percebida | 1-5 | ‚â• 3 | ‚â• 4 |
| Acessibilidade | Conformidade WCAG 2.1 AA | % | ‚â• 85 | ‚â• 95 |
|  | Suporte a tecnologias assistivas | Sim/N√£o | Sim | Sim |

### 3.3 T√©cnicas de Avalia√ß√£o
1. **System Usability Scale (SUS)** ‚Äì question√°rio p√≥s-tarefa; meta SUS ‚â• 20 (aceit√°vel) / ‚â• 50 (excelente).  
2. **Testes de Usabilidade Moderados** ‚Äì 5-10 atendentes, cen√°rios reais, coleta de tempos e erros.  
3. **Avalia√ß√£o Heur√≠stica** ‚Äì 3-5 membros aplicam heur√≠sticas Nielsen.  
4. **Teste de Acessibilidade WCAG** ‚Äì ferramentas Axe/Wave + inspe√ß√£o manual.  
5. **Card Sorting & Tree Testing** ‚Äì valida√ß√£o da arquitetura de informa√ß√£o.  
6. **An√°lise de Logs** ‚Äì monitoramento de cliques e caminhos durante 2 semanas.  
7. **Eye Tracking** (opcional) ‚Äì identificar focos de aten√ß√£o em telas cr√≠ticas.

### 3.4 Instrumentos de Coleta
| # | Instrumento | Objetivo | Formato |
|---|-------------|----------|---------|
| 1 | Question√°rio SUS | Usabilidade percebida | Formul√°rio online |
| 2 | Roteiro de Teste | Medir desempenho real | Script de 8 cen√°rios |
| 3 | Checklist Heur√≠stico | Viola√ß√£o de design | Planilha severidade |
| 4 | Formul√°rio Observa√ß√£o | Registrar erros | Planilha estruturada |
| 5 | Relat√≥rio Acessibilidade | WCAG AA | Export Axe/Wave + notas |
| 6 | Dashboard Logs | M√©tricas de cliques | Grafana |

### 3.5 Procedimento de Avalia√ß√£o
1. **Prepara√ß√£o**: ambiente de teste com base de produtos fict√≠cia; recrutamento de 12 usu√°rios (6 experientes, 6 novos).  
2. **Execu√ß√£o de Sess√µes Moderadas**: coleta de tempo, cliques, erros; aplica√ß√£o do SUS.  
3. **Avalia√ß√£o Heur√≠stica**: especialistas registram problemas e severidade.  
4. **Acessibilidade**: varredura autom√°tica + auditoria manual de 10 telas.  
5. **Card Sorting**: sess√£o remota com 15 usu√°rios para validar categorias.  
6. **Logs em Produ√ß√£o**: an√°lise de duas semanas de uso real.  
7. **S√≠ntese**: c√°lculo do SUS m√©dio; compara√ß√£o de m√©tricas com metas; painel de calor de prioridades.

### 3.6 Cronograma da Fase 2 (Usabilidade)
| Atividade | Dura√ß√£o | Respons√°veis |
|-----------|---------|--------------|
| Defini√ß√£o final de m√©tricas | 2 dias | membros |
| Cria√ß√£o do question√°rio SUS | 3 dias | membros|
| Desenvolvimento de roteiros/scripts | 5 dias | membros |
| Prepara√ß√£o de ambiente | 2 dias | membros |
| Configura√ß√£o de dashboards | 3 dias | membros|
| Valida√ß√£o com stakeholders | 1 dia | membros |
**Total**: **16 dias √∫teis**

### 3.7 Resultados Esperados
‚Ä¢ SUS ‚â• 50 (excelente);  
‚Ä¢ Tempo m√©dio de tarefa ‚â§ 60 s;  
‚Ä¢ Taxa de erros ‚â§ 5 %;  
‚Ä¢ Conformidade WCAG AA ‚â• 95 %;  
‚Ä¢ Relat√≥rio priorizado de problemas de interface.

---

## 4. Gest√£o do Projeto ‚Äì PSM/CID

### 4.1 Calend√°rio do Projeto
‚Ä¢ Cronograma global baseado em Gantt no Trello, cobrindo Fases 1-4 e gest√£o.  
‚Ä¢ Marcos principais: conclus√£o Fase 2 (D+30), execu√ß√£o de testes (D+50), relat√≥rio final (D+70).

### 4.2 Processo Adotado
O grupo utiliza um **processo incremental com Sprints de 2 semanas**:
1. **Sprint 0**: setup ambiente, defini√ß√£o m√©tricas (conclu√≠do).  
2. **Sprint 1**: cria√ß√£o de instrumentos; revis√£o stakeholders.  
3. **Sprint 2**: execu√ß√£o testes piloto; ajustes.  
4. **Sprint 3**: coleta oficial; an√°lise e relat√≥rio.

### 4.3 Performance do Processo
‚Ä¢ At√© o momento, cronograma cumprido em 90 %.  
‚Ä¢ Ajuste realizado: extens√£o de Sprint 1 em +2 dias para refinar question√°rio.  
‚Ä¢ Pontos positivos: comunica√ß√£o √°gil via Slack; pontos negativos: disponibilidade limitada de usu√°rios.

### 4.4 Custo e Recursos
| Recurso | Estimativa | Observa√ß√£o |
|---------|-----------|------------|
| Horas Pessoa 1 | 40 h | Planejamento Fase 1 |
| Horas Pessoa 2 | 80 h | Lideran√ßa Fase 2 |
| Horas Pessoa 3 | 60 h | Design instrumentos |
| Horas Pessoa 4 | 50 h | Execu√ß√£o testes |
| Horas Pessoa 5 | 30 h | Gest√£o projeto |
| Ferramentas | R$ 1.500 | JMeter, SonarQube, Axe licen√ßas |
| Infraestrutura | R$ 800 | Servidor teste + backups |
| Total | **R$ 2.300 + 260 h** | Custos fict√≠cios |

### 4.5 Divis√£o de Responsabilidades
| Integrante | Responsabilidade Principal |
|------------|---------------------------|
| Pessoa 1 | Fase 1 ‚Äì Prop√≥sito |
| Pessoa 2 | Fase 2 ‚Äì Usabilidade |
| Pessoa 3 | Fase 3 ‚Äì Projetar |
| Pessoa 4 | Fase 4 ‚Äì Executar |
| Pessoa 5 | Gest√£o PSM/CID |

---

## 5. Pr√≥ximos Passos
1. **Fase 3 ‚Äì Projetar a Avalia√ß√£o**: transformar instrumentos em roteiro detalhado de execu√ß√£o.  
2. **Fase 4 ‚Äì Executar**: aplicar testes, coletar dados e comparar com crit√©rios.  
3. **Retrospectiva de Processo**: revisar desempenho de Sprints e atualizar estimativas.
